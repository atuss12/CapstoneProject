{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRuMeAH/qfxLYOU78QBeQE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atuss12/CapstoneProject/blob/main/Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNy9ltymfuiz"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community\n",
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Replicate\n",
        "import os\n",
        "from google.colab import userdata\n",
        "# Set the API token\n",
        "api_token = userdata.get('api_token')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token\n",
        "# Model setup\n",
        "model = \"ibm-granite/granite-3.3-8b-instruct\"\n",
        "output = Replicate(\n",
        "model=model,\n",
        "replicate_api_token=api_token,\n",
        ")\n",
        "\n",
        "# Define the customer comments\n",
        "customer_comments = [\n",
        " \"it took so long to arrive.\",\n",
        " \"I don't think I'll buy it again.\",\n",
        " \"very proud to use this local product.\"\n",
        "]\n",
        "# Refine the prompt to include comments\n",
        "customer_comments_text = \"\\n\".join([f\"comment {i+1}: {comment}\" for i, comment\n",
        "in enumerate(customer_comments)])\n",
        "prompt = f\"\"\"\n",
        "Classify these comments as Positive, Negative, or Neutral:\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "# Invoke the model with the example prompt\n",
        "response = output.invoke(prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsRAyoeF_mOP",
        "outputId": "38bf1723-a595-48e0-d21b-98e30dcd9cb4",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Response:\n",
            "\n",
            "1. Negative: The comment \"it took so long to arrive\" expresses dissatisfaction with the delivery time, indicating a negative sentiment.\n",
            "\n",
            "2. Negative: The statement \"I don't think I'll buy it again\" clearly indicates disapproval or dissatisfaction with the product or service, classifying it as negative.\n",
            "\n",
            "3. Positive: The comment \"very proud to use this local product\" expresses satisfaction and appreciation, placing it in the positive category.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define refined prompt\n",
        "refined_prompt = f\"\"\"\n",
        "Classify these reviews as positive, negative, or Neutral, and tag\n",
        "relevant categories (arrive on time, I will not buy again, or like the product):\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "# Invoke the model with the example prompt\n",
        "response = output.invoke(refined_prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Refined Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "PzhnCZw3Rq7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e44ddb00-56c2-4a3b-c97e-8b86145b1f63"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Refined Response:\n",
            "\n",
            "1. Comment: it took so long to arrive.\n",
            "   - Classification: Negative\n",
            "   - Category: Arrive on time\n",
            "\n",
            "2. Comment: I don't think I'll buy it again.\n",
            "   - Classification: Negative\n",
            "   - Category: I will not buy again\n",
            "\n",
            "3. Comment: very proud to use this local product.\n",
            "   - Classification: Positive\n",
            "   - Category: Like the product (implied, as it expresses pride in using the product)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt to complete the task in 2 steps\n",
        "multitask_prompt = f\"\"\"\n",
        "Complete the task in 2 steps.\n",
        "Step 1: Classify these comments as positive, negative, or Neutral.\n",
        "Step 2: For each comment, identify relevant categories: arrive on time, good product, or quality.\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "response = output.invoke(multitask_prompt)\n",
        "print(\"Granite Model Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FnzKsL2TeBuk",
        "outputId": "e0d55f03-e678-4498-e337-40857ec45f98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Response:\n",
            "\n",
            "**Step 1: Classification**\n",
            "\n",
            "1. \"It took so long to arrive.\" - Negative\n",
            "2. \"I don't think I'll buy it again.\" - Negative\n",
            "3. \"Very proud to use this local product.\" - Positive\n",
            "\n",
            "**Step 2: Identification of Relevant Categories**\n",
            "\n",
            "1. \"It took so long to arrive.\" - Relevant categories: arrive on time (Negative)\n",
            "2. \"I don't think I'll buy it again.\" - Relevant categories: good product (Negative)\n",
            "3. \"Very proud to use this local product.\" - Relevant categories: good product, quality (Positive)\n",
            "\n",
            "This classification and categorization respect the instructions, clearly separating the comments into positive, negative, or neutral, and then identifying specific relevant categories for each.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the example to guide the model\n",
        "formatted_prompt = f\"\"\"\n",
        "Classify these comments as Positive, Negative, or Neutral, and tag\n",
        "relevant categories. Use this format:\n",
        "- Sentiment: [Sentiment]\n",
        "- Categories: [Categories].\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "# Invoke the model with prompt\n",
        "response = output.invoke(formatted_prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Formatted Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM-jyXy1huN1",
        "outputId": "035e3d2a-8f03-4273-a924-2817de88717a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Formatted Response:\n",
            "\n",
            "- Sentiment: Negative\n",
            "- Categories: Delivery Time\n",
            "\n",
            "- Sentiment: Negative\n",
            "- Categories: Purchase Intent\n",
            "\n",
            "- Sentiment: Positive\n",
            "- Categories: Product Pride, Local Product Support\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary"
      ],
      "metadata": {
        "id": "L8zW8UQAjKTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_meetings = [\n",
        "\"\"\"\n",
        "Tim data merencanakan analisis terhadap komentar sosial media tentang brand lokal Indonesia\n",
        "seperti Scarlett, MS Glow, dan Kopi Kenangan. Data dikumpulkan dari Twitter, TikTok, dan Instagram, dengan total sekitar 10.000 komentar.\n",
        "Komentar akan diklasifikasikan berdasarkan sentimen (positif, netral, negatif) dan topik utama seperti harga, layanan pelanggan, kualitas produk, pengemasan, dan pengiriman.\n",
        "Model IBM Granite akan digunakan untuk klasifikasi dan ringkasan otomatis. Tujuan akhir proyek adalah menghasilkan insight\n",
        "berbasis data untuk membantu brand memahami persepsi pelanggan dan meningkatkan layanan mereka.A deadline for analytical comments has been set: all results must be submitted by May 30, 2025.\n",
        "\"\"\"\n",
        "]\n",
        "\n",
        "# Refine the prompt to include comments\n",
        "customer_comments_text = \"\\n\".join([f\"comment {i+1}: {comment}\" for i, comment\n",
        "in enumerate(customer_meetings)])\n",
        "prompt = f\"\"\"\n",
        "Summarize this meeting:\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "# Invoke the model with example prompt\n",
        "response = output.invoke(prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Response:\\n\")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "sH2s2Bv7jNCw",
        "outputId": "07f9f396-c317-44cf-f89d-8380065c47ac"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Response:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"In this meeting, Tim proposed an analysis plan to examine social media comments about local Indonesian brands like Scarlett, MS Glow, and Kopi Kenangan. The data, collected from Twitter, TikTok, and Instagram, totals around 10,000 comments. These comments will be classified based on sentiment (positive, neutral, negative) and primary topics such as pricing, customer service, product quality, packaging, and delivery. IBM Granite model will be employed for automatic classification and summarization. The project's ultimate goal is to generate data-driven insights to help brands understand customer perceptions and improve their services. The deadline for submitting analytical results is May 30, 2025.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define refined prompt\n",
        "refined_prompt = f\"\"\"\n",
        "Summarize this meeting in two sentences:\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "# Invoke the model with refined prompt\n",
        "response = output.invoke(refined_prompt)\n",
        "# Print the response\n",
        "print(\"Granite Model Refined Response:\\n\")\n",
        "print(response)\n",
        "\n",
        "# Define the prompt with refined focus area prompt\n",
        "refined_focusarea_prompt = f\"\"\"\n",
        "Summarize this meeting by focusing on key points, decisions made,\n",
        "and action items:\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "response = output.invoke(refined_focusarea_prompt)\n",
        "print(\"Granite Model Response for refined focus area response:\\n\")\n",
        "print(response)\n",
        "\n",
        "# Define the prompt with refined output prompt\n",
        "refined_outputformat_prompt = f\"\"\"\n",
        "Summarize this meeting into a structured format using the following\n",
        "headings: Key Points Discussed, Decisions Made, and Action Items.\n",
        "Mention timelines.\n",
        "Include only two concise bullet points under each heading.\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "response = output.invoke(refined_outputformat_prompt)\n",
        "print(\"Granite Model Response for refined output format response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-wx4zgroYDj",
        "outputId": "b488fa2d-b67b-400c-84fe-f0069949bdfc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Refined Response:\n",
            "\n",
            "The meeting discussion revolved around a product, with one participant expressing dissatisfaction due to delayed delivery, another indicating no intention to repurchase, and a third expressing pride in supporting a local product.\n",
            "Granite Model Response for refined focus area response:\n",
            "\n",
            "The meeting discussion revolved around a local product. Key points included:\n",
            "\n",
            "1. Delays in delivery were noted as a significant issue (comment 1).\n",
            "2. There was a negative sentiment about the purchasing experience, with one participant stating they wouldn't buy it again (comment 2).\n",
            "3. Conversely, another participant expressed pride in supporting a local product (comment 3).\n",
            "\n",
            "Decisions made and action items:\n",
            "\n",
            "1. Acknowledge the delivery delay issue and commit to finding a solution or alternative supplier to prevent future occurrences.\n",
            "2. Investigate the reasons behind dissatisfaction to address any product or service quality concerns that led to the decision not to repurchase (comment 2).\n",
            "3. Highlight and promote the local product's unique selling points to encourage continued support, leveraging the positive sentiment from the participant who values local products (comment 3).\n",
            "\n",
            "Please note that specific decisions or action items cannot be definitively outlined without additional context, as this summary is based on the given comments.\n",
            "Granite Model Response for refined output format response:\n",
            "\n",
            "**Key Points Discussed:**\n",
            "- The lengthy travel time to the meeting was acknowledged.\n",
            "- Pride in supporting local products was expressed.\n",
            "\n",
            "**Decisions Made:**\n",
            "- No formal decisions were made regarding purchasing the product again.\n",
            "- The value of local products was affirmed.\n",
            "\n",
            "**Action Items:**\n",
            "- None directly related to the product purchase, but a suggestion to explore alternative, more accessible local products was proposed.\n",
            "- Timeline: Next monthly meeting for further discussion on local product sourcing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 2"
      ],
      "metadata": {
        "id": "kMiiZY4gs4oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the customer comments\n",
        "customer_comments = [\n",
        " \"it took so long to arrive.\",\n",
        " \"I don't think I'll buy it again.\",\n",
        " \"very proud to use this local product.\"\n",
        "]\n",
        "# Refine the prompt to include comments\n",
        "customer_comments_text= \"\\n\".join([f\"comments {i+1}: {comments}\" for i,\n",
        "comments in enumerate(customer_comments)])\n",
        "\n",
        "# Set model parameters for prompting with default values\n",
        "# Refine multiple Model Parameter values\n",
        "parameters = {\n",
        " \"top_k\": 1,\n",
        " \"top_p\": 0.5,\n",
        " \"max_tokens\": 10,\n",
        " \"min_tokens\": 3,\n",
        " \"random_seed\": None,\n",
        " \"repetition_penalty\": 1.5,\n",
        " \"stopping_criteria\": \"length\",\n",
        " \"stopping_sequence\": None\n",
        "}\n",
        "\n",
        "# Add initial prompt\n",
        "refined_prompt = f\"\"\":\n",
        "Classify these comments as positive, negative, or Neutral, and tag\n",
        "relevant focus areas such as arrive on time, I will not buy again, or like the product\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "# Invoke the model\n",
        "response = output.invoke(refined_prompt, parameters=parameters)\n",
        "# Print the response\n",
        "print(\"Granite Model Refined Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXF3umx8o7au",
        "outputId": "e1c26047-e854-4bda-e6d6-c45d76a23a0e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Refined Response:\n",
            "\n",
            "1. Comment 1: Negative, focus area - arrive on time\n",
            "2. Comment 2: Negative, focus area - I will not buy again\n",
            "3. Comment 3: Positive, focus area - like the product/local product\n",
            "\n",
            "Explanation:\n",
            "\n",
            "1. Comment 1: The statement \"it took so long to arrive\" expresses dissatisfaction with the delivery time, classifying it as a negative comment with a focus area of \"arrive on time.\"\n",
            "\n",
            "2. Comment 2: The phrase \"I don't think I'll buy it again\" indicates a negative sentiment towards the product or service, making it a negative comment with a focus area of \"I will not buy again.\"\n",
            "\n",
            "3. Comment 3: \"Very proud to use this local product\" conveys a positive sentiment about the product, classifying it as a positive comment with a relevant focus area of \"like the product\" or \"local product.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_meetings = [\n",
        "\"\"\"\n",
        "Tim data merencanakan analisis terhadap komentar sosial media tentang brand lokal Indonesia\n",
        "seperti Scarlett, MS Glow, dan Kopi Kenangan. Data dikumpulkan dari Twitter, TikTok, dan Instagram, dengan total sekitar 10.000 komentar.\n",
        "Komentar akan diklasifikasikan berdasarkan sentimen (positif, netral, negatif) dan topik utama seperti harga, layanan pelanggan, kualitas produk, pengemasan, dan pengiriman.\n",
        "Model IBM Granite akan digunakan untuk klasifikasi dan ringkasan otomatis. Tujuan akhir proyek adalah menghasilkan insight\n",
        "berbasis data untuk membantu brand memahami persepsi pelanggan dan meningkatkan layanan mereka.A deadline for analytical comments has been set: all results must be submitted by May 30, 2025.\n",
        "\"\"\"\n",
        "]\n",
        "# Refine the prompt to include comments\n",
        "customer_comments_text= \"\\n\".join([f\"comments {i+1}: {comments}\" for i,\n",
        "comments in enumerate(customer_comments)])\n",
        "\n",
        "# Refine max_tokens parameter value\n",
        "parameters = {\n",
        "\"top_k\": 0,\n",
        "\"top_p\": 1.0,\n",
        "\"max_tokens\": 20,\n",
        "\"min_tokens\": 0,\n",
        "\"random_seed\": None,\n",
        "\"repetition_penalty\": 1.0,\n",
        "\"stopping_criteria\": \"length (256 tokens)\",\n",
        "\"stopping_sequence\": None\n",
        "}\n",
        "\n",
        "# Refined prompt with example included\n",
        "refined_focus_prompt = f\"\"\"\n",
        "Summarize this meeting by focusing on key points, decisions, and\n",
        "action items\n",
        "{customer_comments_text}\n",
        "\"\"\"\n",
        "# Invoke the model with the refined focus prompt\n",
        "response = output.invoke(refined_focus_prompt,\n",
        "parameters=parameters)\n",
        "# Print the response\n",
        "print(\"Granite Model Response for refined focus area response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IX9NJ0LwvTH",
        "outputId": "b6520d48-7aaa-45a0-bf1c-29fa4e109f3d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Response for refined focus area response:\n",
            "\n",
            "Key Points:\n",
            "- The meeting discussed a product, implying a potential review or feedback session.\n",
            "- There were mixed reactions regarding the product's delivery time and quality.\n",
            "\n",
            "Decisions:\n",
            "- No explicit decisions were mentioned in the provided comments.\n",
            "\n",
            "Action Items:\n",
            "- Reconsider purchasing the product due to the extended delivery time (from comment 1 and 2).\n",
            "- Continue supporting local products, suggesting potential promotion or further investigation of the product's quality and delivery process (from comment 3).\n",
            "\n",
            "Summary:\n",
            "The meeting focused on a local product, with participants expressing dissatisfaction over prolonged delivery times (comments 1 and 2). This may lead to reconsidering future purchases. However, there is also appreciation for the product's local origin (comment 3), suggesting an action item to investigate and potentially promote the product further, addressing concerns about delivery times to enhance customer satisfaction.\n"
          ]
        }
      ]
    }
  ]
}